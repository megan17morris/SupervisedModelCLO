{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fe3735",
   "metadata": {},
   "source": [
    "Required packages:\\\n",
    "pandas==1.4.0\\\n",
    "numpy==1.21.5\\\n",
    "scikit-learn==1.0.2\\\n",
    "tensorflow==2.7.0\\\n",
    "torch==1.10.2\\\n",
    "transformers==4.17.0.dev0\\\n",
    "datasets==1.18.3\\\n",
    "textstat==0.7.2 (if running the ML part)\\\n",
    "xgboost==1.5.2 (if running the ML part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7611427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "883b3b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Learning_outcome  Remember  Understand  \\\n",
      "0   Analyze the health economic implications of e...       NaN         NaN   \n",
      "1   Apply research skills to operate effectively ...       NaN         NaN   \n",
      "2   Assess and synthesise diverse information abo...       NaN         NaN   \n",
      "3   Describe the general characteristics of the m...       NaN         1.0   \n",
      "4   Evaluate the different models of perioperativ...       NaN         NaN   \n",
      "\n",
      "   Apply  Analyze  Evaluate  Create  \n",
      "0    NaN      1.0       NaN     NaN  \n",
      "1    1.0      NaN       NaN     NaN  \n",
      "2    NaN      NaN       1.0     1.0  \n",
      "3    NaN      NaN       NaN     NaN  \n",
      "4    NaN      NaN       1.0     NaN  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/sample_full.csv\", nrows=10)\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f93d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'Remember': 0, 'Understand': 0, 'Apply': 0, 'Analyze': 0, 'Evaluate': 0, 'Create':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "558e721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_data = pd.read_csv(\"data/LIWC2015 Results (Learning_outcome.csv).csv\")\n",
    "data = data.join(LIWC_data).drop(['A'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3bbe570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_outcome</th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the health economic implications of e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>99.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apply research skills to operate effectively ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>99.00</td>\n",
       "      <td>92.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assess and synthesise diverse information abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>43.96</td>\n",
       "      <td>77.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the general characteristics of the m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>99.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate the different models of perioperativ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>98.58</td>\n",
       "      <td>15.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Learning_outcome  Remember  Understand  \\\n",
       "0   Analyze the health economic implications of e...       0.0         0.0   \n",
       "1   Apply research skills to operate effectively ...       0.0         0.0   \n",
       "2   Assess and synthesise diverse information abo...       0.0         0.0   \n",
       "3   Describe the general characteristics of the m...       0.0         1.0   \n",
       "4   Evaluate the different models of perioperativ...       0.0         0.0   \n",
       "\n",
       "   Apply  Analyze  Evaluate  Create  WC  Analytic  Clout  ...  Comma  Colon  \\\n",
       "0    0.0      1.0       0.0     0.0   9     99.00  50.00  ...    0.0    0.0   \n",
       "1    1.0      0.0       0.0     0.0  14     99.00  92.33  ...    0.0    0.0   \n",
       "2    0.0      0.0       1.0     1.0  26     43.96  77.92  ...    0.0    0.0   \n",
       "3    0.0      0.0       0.0     0.0  23     99.00  50.00  ...    8.7    0.0   \n",
       "4    0.0      0.0       1.0     0.0  10     98.58  15.86  ...    0.0    0.0   \n",
       "\n",
       "   SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "1    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "2    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "3    0.0    0.0     0.0  4.35    0.0      0.0      0.0     0.0  \n",
       "4    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "738e8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[data.columns[1:7]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "206bd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Remember', 'Understand', 'Apply', 'Analyze', 'Evaluate', 'Create'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "506c390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9b29a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, cohen_kappa_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5be46",
   "metadata": {},
   "source": [
    "## ML Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f1ad0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96309d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateX(data_x, test_x, textual_column_index, start_index_LIWC, end_index_LIWC):\n",
    "    column_names = []\n",
    "    print(\"Getting Unigram...\")\n",
    "    uni_cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    unigram = uni_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    unigram = unigram.toarray()\n",
    "    unigram_test = uni_cv.transform(test_x[:,textual_column_index]).toarray()\n",
    "    temp = uni_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"uni_\"+name for name in temp]\n",
    "    print(\"Getting Bigram...\")\n",
    "    bi_cv = CountVectorizer(stop_words='english', ngram_range=(2, 2), max_features=1000)\n",
    "    bigram = bi_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    bigram = bigram.toarray()\n",
    "    bigram_test = bi_cv.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = bi_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"bi_\"+name for name in temp]\n",
    "    print(\"Getting Tfidf...\")\n",
    "    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    t = tfidf.fit_transform(data_x[:, textual_column_index])\n",
    "    t = t.toarray()\n",
    "    t_test = tfidf.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = tfidf.get_feature_names_out().tolist()\n",
    "    column_names += [\"tfidf_\"+name for name in temp]\n",
    "    print(\"Getting ARI...\")\n",
    "    ari = [textstat.automated_readability_index(text) for text in data_x[:, textual_column_index]]\n",
    "    ari_test = [textstat.automated_readability_index(text) for text in test_x[:, textual_column_index]]\n",
    "    column_names.append(\"ari\")\n",
    "    combined_data_x = []\n",
    "    combined_test_x = []\n",
    "    print(\"Combining...\")\n",
    "    for i in range(len(data_x)):\n",
    "        combined_data_x.append(unigram[i].tolist()\n",
    "                              + bigram[i].tolist()\n",
    "                              + t[i].tolist()\n",
    "                              + [ari[i]]\n",
    "                              + data_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    for i in range(len(test_x)):\n",
    "        combined_test_x.append(unigram_test[i].tolist()\n",
    "                              + bigram_test[i].tolist()\n",
    "                              + t_test[i].tolist()\n",
    "                              + [ari_test[i]]\n",
    "                              + test_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    print(\"Generated feature shape is\", np.array(combined_data_x).shape)\n",
    "    print(\"Generated test feature is\", np.array(combined_test_x).shape)\n",
    "    return combined_data_x, column_names, combined_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d575655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Analyze the health economic implications of e...\n",
       "1     Apply research skills to operate effectively ...\n",
       "2     Assess and synthesise diverse information abo...\n",
       "3     Describe the general characteristics of the m...\n",
       "4     Evaluate the different models of perioperativ...\n",
       "5     explain key terms and concepts used to engage...\n",
       "6     Identify an issue of relevance to the practic...\n",
       "7     Identify the key features of the use of radia...\n",
       "8     Recognise the key role that human factors pla...\n",
       "9     Rigorously quantify the mixing of various cla...\n",
       "Name: Learning_outcome, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=list(data.columns[1:7])).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "592e391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data.drop(columns=list(data.columns[1:8])), data[data.columns[1:7]], test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e72037dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([7, 1])), (array([0.]), array([2])))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Remember'].tolist(), return_counts=True), np.unique(test_y['Remember'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7a8e740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([7, 1])), (array([0., 1.]), array([1, 1])))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Understand'].tolist(), return_counts=True), np.unique(test_y['Understand'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a0155c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([6, 2])), (array([0.]), array([2])))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Apply'].tolist(), return_counts=True), np.unique(test_y['Apply'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fde5b0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([6, 2])), (array([0., 1.]), array([1, 1])))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Analyze'].tolist(), return_counts=True), np.unique(test_y['Analyze'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "819bd6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([6, 2])), (array([0.]), array([2])))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Evaluate'].tolist(), return_counts=True), np.unique(test_y['Evaluate'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57bb7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([7, 1])), (array([0.]), array([2])))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Create'].tolist(), return_counts=True), np.unique(test_y['Create'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8315a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([9, 1]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = []\n",
    "for d in data[data.columns[1:7]].values:\n",
    "    one_hot.append(np.array2string(d).count(\"1\"))\n",
    "np.unique(one_hot, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6008a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (8, 326)\n",
      "Generated test feature is (2, 326)\n"
     ]
    }
   ],
   "source": [
    "ml_train_x, column_names, ml_test_x = generateX(train_x.to_numpy(), test_x.to_numpy(), 0, 1, 94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4393f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names += data.columns[7:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35d7e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(ml_train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "722b4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = rf.predict(ml_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddeb617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Remember      0.000     0.000     0.000         0\n",
      "  Understand      0.000     0.000     0.000         1\n",
      "       Apply      0.000     0.000     0.000         0\n",
      "     Analyze      0.000     0.000     0.000         1\n",
      "    Evaluate      0.000     0.000     0.000         0\n",
      "      Create      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.000     0.000     0.000         2\n",
      "   macro avg      0.000     0.000     0.000         2\n",
      "weighted avg      0.000     0.000     0.000         2\n",
      " samples avg      0.000     0.000     0.000         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y, output_dict=False, target_names=list(data.columns[1:7]), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2796b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_y = rf.predict_proba(ml_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "491b5a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 93)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf029020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_score_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91fa2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_y = np.transpose([score[:, 1] for score in rf.predict_proba(ml_test_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac9ad3fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_score_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:575\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    568\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    569\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_base.py:118\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    117\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m--> 118\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:337\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    342\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "roc_auc_score(test_y, pred_score_y, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ab923",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_y, pred_y, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e579641",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_result_df = pd.DataFrame(data=pred_y, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2ad2b6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_result_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_result_df' is not defined"
     ]
    }
   ],
   "source": [
    "ml_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fba1ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_golden_df = pd.DataFrame(data=test_y, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "203d209c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(ml_golden_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemember\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), \u001b[43mml_result_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemember\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(ml_golden_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnderstand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), ml_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnderstand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(ml_golden_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApply\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), ml_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApply\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_result_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ml_golden_df['Remember'].tolist(), ml_result_df['Remember'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Understand'].tolist(), ml_result_df['Understand'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Apply'].tolist(), ml_result_df['Apply'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Analyze'].tolist(), ml_result_df['Analyze'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Evaluate'].tolist(), ml_result_df['Evaluate'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Create'].tolist(), ml_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d286e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(cohen_kappa_score(ml_golden_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemember\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), \u001b[43mml_result_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemember\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cohen_kappa_score(ml_golden_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnderstand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), ml_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnderstand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cohen_kappa_score(ml_golden_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApply\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), ml_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApply\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_result_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(ml_golden_df['Remember'].tolist(), ml_result_df['Remember'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Understand'].tolist(), ml_result_df['Understand'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Apply'].tolist(), ml_result_df['Apply'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Analyze'].tolist(), ml_result_df['Analyze'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Evaluate'].tolist(), ml_result_df['Evaluate'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Create'].tolist(), ml_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940215e9",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8f11046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import TFBertPreTrainedModel, TFBertMainLayer, InputFeatures\n",
    "from datasets import load_metric, list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0af84439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "740bae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/huggingface_hub-0.23.4-py3.8.egg/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like multilabel/checkpoint-250 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/transformers/utils/hub.py:399\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/huggingface_hub-0.23.4-py3.8.egg/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/huggingface_hub-0.23.4-py3.8.egg/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/huggingface_hub-0.23.4-py3.8.egg/huggingface_hub/file_download.py:1325\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/huggingface_hub-0.23.4-py3.8.egg/huggingface_hub/file_download.py:1817\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_files_only:\n\u001b[0;32m-> 1817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1818\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1819\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m hf.co look-ups and downloads online, set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1820\u001b[0m     )\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: Cannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable hf.co look-ups and downloads online, set 'local_files_only' to False.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultilabel/checkpoint-250\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:523\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 523\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:934\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    932\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    936\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supervisedModel/lib/python3.10/site-packages/transformers/utils/hub.py:442\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    437\u001b[0m         resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors\n\u001b[1;32m    440\u001b[0m     ):\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this file, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like multilabel/checkpoint-250 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', problem_type=\"multi_label_classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('multilabel/checkpoint-250', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4808e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data['Learning_outcome'].tolist(), labels, test_size=0.2, random_state=666)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "107a3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = tokenizer(train_x, truncation=True, padding=True, max_length=100)\n",
    "val_encoded = tokenizer(val_x, truncation=True, padding=True, max_length=100)\n",
    "test_encoded = tokenizer(test_x, truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dfe437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = EncodeDataset(train_encoded, train_y), EncodeDataset(val_encoded, val_y), EncodeDataset(test_encoded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af89acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir='multilabel',          # output directory\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=3,              # total number of training epochs\n",
    "        per_device_train_batch_size=64,  # batch size per device during training\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        warmup_steps=5,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.05,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=10,\n",
    "        load_best_model_at_end=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64f828cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassResult(predicted):\n",
    "    results = []\n",
    "    for probs in predicted.numpy():\n",
    "        result = []\n",
    "        for prob in probs:\n",
    "            if prob < 0.5:\n",
    "                result.append(0)\n",
    "            else:\n",
    "                result.append(1)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = tf.keras.activations.sigmoid(logits)\n",
    "    predicted = getClassResult(predictions)\n",
    "    return metric.compute(predictions=predicted, references=labels, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebca9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_set, eval_dataset=val_set, callbacks=[EarlyStoppingCallback(early_stopping_patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbae7c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/642 1:11:45 < 1:22:20, 0.07 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.320655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.272382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.277200</td>\n",
       "      <td>0.240769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.194180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.182231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.169153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.163196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.160195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.149396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.154515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.140491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.137786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.132561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>0.130889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>0.128218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.139436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.124558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.125121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.117832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.118813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.119164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.113883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.111960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.114039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.115314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.114011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.114620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.116487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-10\n",
      "Configuration saved in multilabel/checkpoint-10/config.json\n",
      "Model weights saved in multilabel/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-20\n",
      "Configuration saved in multilabel/checkpoint-20/config.json\n",
      "Model weights saved in multilabel/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-30\n",
      "Configuration saved in multilabel/checkpoint-30/config.json\n",
      "Model weights saved in multilabel/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-40\n",
      "Configuration saved in multilabel/checkpoint-40/config.json\n",
      "Model weights saved in multilabel/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-50\n",
      "Configuration saved in multilabel/checkpoint-50/config.json\n",
      "Model weights saved in multilabel/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-60\n",
      "Configuration saved in multilabel/checkpoint-60/config.json\n",
      "Model weights saved in multilabel/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-70\n",
      "Configuration saved in multilabel/checkpoint-70/config.json\n",
      "Model weights saved in multilabel/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-80\n",
      "Configuration saved in multilabel/checkpoint-80/config.json\n",
      "Model weights saved in multilabel/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-90\n",
      "Configuration saved in multilabel/checkpoint-90/config.json\n",
      "Model weights saved in multilabel/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-100\n",
      "Configuration saved in multilabel/checkpoint-100/config.json\n",
      "Model weights saved in multilabel/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-110\n",
      "Configuration saved in multilabel/checkpoint-110/config.json\n",
      "Model weights saved in multilabel/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-120\n",
      "Configuration saved in multilabel/checkpoint-120/config.json\n",
      "Model weights saved in multilabel/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-130\n",
      "Configuration saved in multilabel/checkpoint-130/config.json\n",
      "Model weights saved in multilabel/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-140\n",
      "Configuration saved in multilabel/checkpoint-140/config.json\n",
      "Model weights saved in multilabel/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-150\n",
      "Configuration saved in multilabel/checkpoint-150/config.json\n",
      "Model weights saved in multilabel/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-160\n",
      "Configuration saved in multilabel/checkpoint-160/config.json\n",
      "Model weights saved in multilabel/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-170\n",
      "Configuration saved in multilabel/checkpoint-170/config.json\n",
      "Model weights saved in multilabel/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-180\n",
      "Configuration saved in multilabel/checkpoint-180/config.json\n",
      "Model weights saved in multilabel/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-190\n",
      "Configuration saved in multilabel/checkpoint-190/config.json\n",
      "Model weights saved in multilabel/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-200\n",
      "Configuration saved in multilabel/checkpoint-200/config.json\n",
      "Model weights saved in multilabel/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-210\n",
      "Configuration saved in multilabel/checkpoint-210/config.json\n",
      "Model weights saved in multilabel/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-220\n",
      "Configuration saved in multilabel/checkpoint-220/config.json\n",
      "Model weights saved in multilabel/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-230\n",
      "Configuration saved in multilabel/checkpoint-230/config.json\n",
      "Model weights saved in multilabel/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-240\n",
      "Configuration saved in multilabel/checkpoint-240/config.json\n",
      "Model weights saved in multilabel/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-250\n",
      "Configuration saved in multilabel/checkpoint-250/config.json\n",
      "Model weights saved in multilabel/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-260\n",
      "Configuration saved in multilabel/checkpoint-260/config.json\n",
      "Model weights saved in multilabel/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-270\n",
      "Configuration saved in multilabel/checkpoint-270/config.json\n",
      "Model weights saved in multilabel/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-280\n",
      "Configuration saved in multilabel/checkpoint-280/config.json\n",
      "Model weights saved in multilabel/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-290\n",
      "Configuration saved in multilabel/checkpoint-290/config.json\n",
      "Model weights saved in multilabel/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-300\n",
      "Configuration saved in multilabel/checkpoint-300/config.json\n",
      "Model weights saved in multilabel/checkpoint-300/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from multilabel/checkpoint-250 (score: 0.1119597777724266).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.15403384764989217, metrics={'train_runtime': 4311.8885, 'train_samples_per_second': 9.52, 'train_steps_per_second': 0.149, 'total_flos': 986033813713200.0, 'train_loss': 0.15403384764989217, 'epoch': 1.4})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f14bc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 01:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = trainer.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0750e38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5b7a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:49:38.848119: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-10 00:49:38.848561: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.keras.activations.sigmoid(logits.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f33fc8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01409502, 0.9816279 , 0.01466793, 0.0106061 , 0.01333568,\n",
       "        0.01498337],\n",
       "       [0.01131314, 0.97574437, 0.01378885, 0.00961971, 0.01381588,\n",
       "        0.01985262],\n",
       "       [0.01220088, 0.25224018, 0.02930349, 0.01424369, 0.41727734,\n",
       "        0.00650762],\n",
       "       ...,\n",
       "       [0.00437115, 0.01897231, 0.95080817, 0.00888529, 0.01537037,\n",
       "        0.03060839],\n",
       "       [0.60755473, 0.33469725, 0.02623363, 0.0142573 , 0.8560901 ,\n",
       "        0.01503711],\n",
       "       [0.00936071, 0.02604666, 0.5798291 , 0.02834429, 0.9835946 ,\n",
       "        0.05021281]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acea92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = getClassResult(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d53a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for pred in predicted_label:\n",
    "    if pred.count(1) > 1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0899422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Remember      0.860     0.852     0.856       237\n",
      "  Understand      0.921     0.918     0.920      1200\n",
      "       Apply      0.929     0.895     0.912      1216\n",
      "     Analyze      0.939     0.877     0.907       701\n",
      "    Evaluate      0.947     0.914     0.930       799\n",
      "      Create      0.915     0.832     0.872       739\n",
      "\n",
      "   micro avg      0.926     0.890     0.907      4892\n",
      "   macro avg      0.919     0.881     0.899      4892\n",
      "weighted avg      0.926     0.890     0.907      4892\n",
      " samples avg      0.919     0.907     0.907      4892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predicted_label, output_dict=False, target_names=list(data.columns[1:7]), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e52f7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98839375, 0.98205773, 0.97611275, 0.98406073, 0.98888998,\n",
       "       0.97096306])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, predicted.numpy(), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c01e8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528999064546305"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(test_y), predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4bcd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_result_df = pd.DataFrame(data=predicted_label, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4d4dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9840972871842844\n",
      "0.9550982226379794\n",
      "0.9506548175865295\n",
      "0.970533208606174\n",
      "0.9742750233863424\n",
      "0.9576707202993452\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ml_golden_df['Remember'].tolist(), dl_result_df['Remember'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Understand'].tolist(), dl_result_df['Understand'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Apply'].tolist(), dl_result_df['Apply'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Analyze'].tolist(), dl_result_df['Analyze'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Evaluate'].tolist(), dl_result_df['Evaluate'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Create'].tolist(), dl_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9b0db2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475165217354823\n",
      "0.8886774810112577\n",
      "0.8773959293050357\n",
      "0.8895938602599291\n",
      "0.9141876451080061\n",
      "0.8464440044283781\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(ml_golden_df['Remember'].tolist(), dl_result_df['Remember'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Understand'].tolist(), dl_result_df['Understand'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Apply'].tolist(), dl_result_df['Apply'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Analyze'].tolist(), dl_result_df['Analyze'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Evaluate'].tolist(), dl_result_df['Evaluate'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Create'].tolist(), dl_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
