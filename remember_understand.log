Running models for Remember task...
n_iterations: 2
n_required_iterations: 2
n_possible_iterations: 2
min_resources_: 5701
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 3
n_resources: 5701
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV 1/3] END var_smoothing=1e-09;, score=(train=0.588, test=0.187) total time=   2.3s
[CV 1/3] END var_smoothing=1e-08;, score=(train=0.301, test=0.196) total time=  11.0s
[CV 1/3] END C=0.1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   2.8s
[CV 3/3] END C=0.1, gamma=auto, kernel=poly;, score=(train=0.783, test=0.113) total time=   3.7s
[CV 3/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.441) total time=   4.2s
[CV 3/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.441) total time=   4.0s
[CV 2/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.641) total time=   4.6s
[CV 3/3] END C=10, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   2.6s
[CV 1/3] END C=100, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.000) total time=   4.0s
[CV 2/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.657) total time=  48.5s
[CV 1/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.716) total time= 1.1min
[CV 3/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.656) total time=  39.6s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
----------
iter: 1
n_candidates: 1
n_resources: 17103
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Time taken to train Naive Bayes for Remember:  54.78927707672119
Best parameters for Naive Bayes for Remember:  {'var_smoothing': 1e-08}
Accuracy for Naive Bayes for Remember 0.6431244153414406
Accuracy Score ->  0.6431244153414406
Kappa Score ->  0.11330067468864435
ROC AUC Score ->  0.7177540081254185
F1 Score ->  0.1993704092339979
Classification report -> 
               precision    recall  f1-score   support

           0       0.98      0.63      0.77      4039
           1       0.11      0.80      0.20       237

    accuracy                           0.64      4276
   macro avg       0.55      0.72      0.48      4276
weighted avg       0.93      0.64      0.74      4276

Accuracy for Naive Bayes for Remember with Auto:  0.7
Accuracy Score ->  0.7
Kappa Score ->  -0.10619469026548689
ROC AUC Score ->  0.4605263157894737
F1 Score ->  0.0
Classification report -> 
               precision    recall  f1-score   support

           0       0.74      0.92      0.82        38
           1       0.00      0.00      0.00        12

    accuracy                           0.70        50
   macro avg       0.37      0.46      0.41        50
weighted avg       0.57      0.70      0.63        50

n_iterations: 3
n_required_iterations: 3
n_possible_iterations: 3
min_resources_: 1900
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 24
n_resources: 1900
Fitting 3 folds for each of 24 candidates, totalling 72 fits
----------
iter: 1
n_candidates: 8
n_resources: 5700
Fitting 3 folds for each of 8 candidates, totalling 24 fits
----------
iter: 2
n_candidates: 3
n_resources: 17100
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV 3/3] END var_smoothing=1e-08;, score=(train=0.609, test=0.229) total time=   3.8s
[CV 1/3] END C=0.1, gamma=auto, kernel=poly;, score=(train=0.857, test=0.136) total time=   3.3s
[CV 1/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.533) total time=   4.7s
[CV 1/3] END C=1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   3.0s
[CV 1/3] END C=1, gamma=auto, kernel=poly;, score=(train=1.000, test=0.241) total time=   3.6s
[CV 3/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.441) total time=   4.0s
[CV 3/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.441) total time=   4.0s
[CV 1/3] END C=100, gamma=scale, kernel=poly;, score=(train=0.836, test=0.140) total time=   3.1s
[CV 1/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.533) total time=   3.6s
[CV 2/3] END C=100, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.077) total time=   4.4s
[CV 2/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.902, test=0.636) total time=  35.3s
[CV 1/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.725) total time=  57.4s
[CV 3/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.667) total time= 1.6min
[CV 2/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.881, test=0.771) total time=18.6min
Time taken to train SVM for Remember:  1918.5817008018494
Best parameters for SVM for Remember:  {'C': 0.1, 'gamma': 'auto', 'kernel': 'linear'}
Accuracy for SVM for Remember 0.980355472404116
Accuracy Score ->  0.980355472404116
Kappa Score ->  0.813128417503863
ROC AUC Score ->  0.9081790099274689
F1 Score ->  0.8235294117647058
Classification report -> 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99      4039
           1       0.82      0.83      0.82       237

    accuracy                           0.98      4276
   macro avg       0.90      0.91      0.91      4276
weighted avg       0.98      0.98      0.98      4276

Accuracy for SVM for Remember with Auto:  0.74
Accuracy Score ->  0.74
Kappa Score ->  -0.03833865814696491
ROC AUC Score ->  0.4868421052631579
F1 Score ->  0.0
Classification report -> 
               precision    recall  f1-score   support

           0       0.76      0.97      0.85        38
           1       0.00      0.00      0.00        12

    accuracy                           0.74        50
   macro avg       0.38      0.49      0.43        50
weighted avg       0.57      0.74      0.65        50

n_iterations: 4
n_required_iterations: 4
n_possible_iterations: 4
min_resources_: 633
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 54
n_resources: 633
Fitting 3 folds for each of 54 candidates, totalling 162 fits
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 1/3] END var_smoothing=1e-08;, score=(train=0.588, test=0.187) total time=   1.5s
[CV 1/3] END var_smoothing=1e-10;, score=(train=0.588, test=0.187) total time=   2.3s
[CV 1/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.885, test=0.440) total time=   2.6s
[CV 3/3] END C=0.1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   3.3s
[CV 1/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.885, test=0.440) total time=   3.9s
[CV 2/3] END C=0.1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.8s
[CV 2/3] END C=1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   3.9s
[CV 1/3] END C=1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.4s
[CV 2/3] END C=10, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   3.2s
[CV 3/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.441) total time=   4.2s
[CV 3/3] END C=100, gamma=scale, kernel=rbf;, score=(train=0.742, test=0.091) total time=   3.0s
[CV 2/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.902, test=0.636) total time=  42.6s
[CV 1/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.716) total time=  58.9s
[CV 3/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.667) total time= 1.2min
[CV 1/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.890, test=0.797) total time=18.8min
[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.5s
[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   1.4s
[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.5s
[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   1.4s
[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.000, test=0.000) total time=   4.6s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 2/3] END var_smoothing=1e-08;, score=(train=0.604, test=0.224) total time=   2.5s
[CV 2/3] END var_smoothing=1e-08;, score=(train=0.312, test=0.194) total time=  10.3s
[CV 3/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.925, test=0.235) total time=   3.7s
[CV 3/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.925, test=0.235) total time=   3.7s
[CV 1/3] END C=1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   2.9s
[CV 3/3] END C=1, gamma=auto, kernel=poly;, score=(train=1.000, test=0.222) total time=   3.6s
[CV 1/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.533) total time=   4.5s
[CV 1/3] END C=10, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   3.0s
[CV 2/3] END C=10, gamma=auto, kernel=poly;, score=(train=1.000, test=0.162) total time=   3.3s
[CV 3/3] END C=10, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.095) total time=   4.0s
[CV 1/3] END C=100, gamma=scale, kernel=rbf;, score=(train=0.788, test=0.114) total time=   3.4s
[CV 3/3] END C=100, gamma=auto, kernel=poly;, score=(train=1.000, test=0.222) total time=   2.9s
[CV 3/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.926, test=0.722) total time=  44.8s
[CV 2/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.657) total time=  56.9s
[CV 1/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.725) total time= 1.1min
[CV 2/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.881, test=0.771) total time=18.1min
[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.4s
[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.100, test=0.000) total time=   1.5s
[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.000, test=0.000) total time=   1.6s
[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   1.2s
[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.261, test=0.143) total time=   1.3s
[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.000, test=0.000) total time=   3.6s
[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.000, test=0.000) total time=   4.7s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 3/3] END var_smoothing=1e-09;, score=(train=0.607, test=0.229) total time=   2.4s
[CV 2/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.930, test=0.567) total time=   3.2s
[CV 2/3] END C=0.1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   3.4s
[CV 2/3] END C=0.1, gamma=auto, kernel=poly;, score=(train=0.823, test=0.145) total time=   5.0s
[CV 1/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.533) total time=   3.9s
[CV 2/3] END C=1, gamma=auto, kernel=rbf;, score=(train=0.079, test=0.050) total time=   5.0s
[CV 2/3] END C=10, gamma=scale, kernel=poly;, score=(train=0.053, test=0.000) total time=   3.3s
[CV 1/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.533) total time=   3.8s
[CV 1/3] END C=10, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.000) total time=   4.2s
[CV 3/3] END C=100, gamma=scale, kernel=poly;, score=(train=0.756, test=0.113) total time=   3.0s
[CV 3/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.441) total time=   3.9s
[CV 1/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.922, test=0.725) total time=  41.7s
[CV 3/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.656) total time= 1.0min
[CV 2/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.657) total time= 1.5min
[CV 1/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.890, test=0.797) total time=18.1min
[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.000, test=0.000) total time=   1.6s
[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.6s
[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.8s
[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   3.7s
[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.9s
[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   3.7s
[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.190, test=0.143) total time=   1.7s
[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.231, test=0.000) total time=   1.7s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 2/3] END var_smoothing=1e-09;, score=(train=0.602, test=0.219) total time=   2.6s
[CV 3/3] END var_smoothing=1e-08;, score=(train=0.305, test=0.179) total time=   8.0s
[CV 3/3] END C=0.1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   2.8s
[CV 1/3] END C=0.1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   5.8s
[CV 3/3] END C=10, gamma=scale, kernel=poly;, score=(train=0.164, test=0.051) total time=   2.7s
[CV 1/3] END C=10, gamma=auto, kernel=poly;, score=(train=1.000, test=0.241) total time=   3.3s
[CV 2/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.641) total time=   4.0s
[CV 2/3] END C=100, gamma=scale, kernel=rbf;, score=(train=0.752, test=0.082) total time=   3.8s
[CV 2/3] END C=100, gamma=auto, kernel=poly;, score=(train=1.000, test=0.162) total time=   3.3s
[CV 1/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.922, test=0.725) total time=  34.8s
[CV 3/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.667) total time=  56.6s
[CV 2/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.657) total time= 1.3min
[CV 1/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.694) total time=18.4min
[CV 3/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.881, test=0.784) total time= 1.4min
[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.182, test=0.143) total time=   1.3s
[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   1.3s
[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   1.9s
[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.6s
[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.6s
[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.7s
[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.190, test=0.143) total time=   1.7s
[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.261, test=0.143) total time=   1.6s
[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   1.4s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=   4.1s
[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   3.5s
[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.452, test=0.000) total time=   3.9s
[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.7s
[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.5s
[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   1.5s
[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.6s
[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   1.4s
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.6s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.519, test=0.267) total time=   5.8s
[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.452, test=0.000) total time=   4.2s
[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   2.7s
[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.6s
[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.6s
[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.261, test=0.143) total time=   1.8s
[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   1.1s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.9s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   5.3s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.9s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   4.9s
[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.227, test=0.000) total time=   6.3s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.245, test=0.000) total time=  24.9s
[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  37.5s
[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.209, test=0.140) total time=  19.3s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
----------
iter: 1
n_candidates: 18
n_resources: 1899
Fitting 3 folds for each of 18 candidates, totalling 54 fits
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 3/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.719) total time=19.5min
[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.000, test=0.000) total time=   1.5s
[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.5s
[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.261, test=0.143) total time=   1.6s
[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.000, test=0.000) total time=   4.2s
[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.160, test=0.000) total time=   0.7s
[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.231, test=0.000) total time=   1.7s
[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.5s
[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.261, test=0.143) total time=   1.5s
[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.261, test=0.143) total time=   1.5s
[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.160, test=0.000) total time=   0.6s
[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.452, test=0.000) total time=   4.2s
[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.6s
[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=   4.8s
[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.261, test=0.143) total time=   1.8s
[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   2.0s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   1.2s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.452, test=0.000) total time=   5.2s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=   4.2s
[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.098) total time=   7.2s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  19.2s
[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  37.5s
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.182, test=0.143) total time=  25.3s
[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  18.5s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.414, test=0.000) total time=   4.0s
[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=   4.0s
[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   1.7s
[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.6s
[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.6s
[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.261, test=0.143) total time=   1.4s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.519, test=0.267) total time=   4.4s
[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   3.5s
[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   4.1s
[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   1.2s
[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.261, test=0.143) total time=   2.7s
[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.6s
[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.261, test=0.143) total time=   1.8s
[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   1.1s
[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.452, test=0.000) total time=   9.9s
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.160, test=0.000) total time=   0.8s
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.452, test=0.000) total time=   3.9s
[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.062, test=0.000) total time=   6.9s
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  24.6s
[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.209, test=0.140) total time=  38.1s
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  25.4s
[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.209, test=0.140) total time=  19.3s
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  19.9s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
----------
iter: 2
n_candidates: 6
n_resources: 5697
Fitting 3 folds for each of 6 candidates, totalling 18 fits
[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.100, test=0.000) total time=   1.5s
[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   1.3s
[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.4s
[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   3.4s
[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.414, test=0.000) total time=   4.3s
[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.452, test=0.000) total time=   3.8s
[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.8s
[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   1.4s
[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   1.4s
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.400, test=0.000) total time=   4.9s
[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   3.6s
[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.7s
[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   1.8s
[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   1.1s
[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   9.7s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   5.6s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.209, test=0.140) total time=  19.1s
[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.209, test=0.140) total time=  18.6s
[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  18.7s
[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  19.5s
[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  18.9s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.209, test=0.140) total time=  20.4s
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  14.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.160, test=0.000) total time=   0.7s
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.345, test=0.000) total time=   5.7s
[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.7s
[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   4.6s
[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   2.6s
[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   2.8s
[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.261, test=0.143) total time=   1.7s
[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   1.7s
[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.452, test=0.000) total time=  10.2s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   4.4s
[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.098) total time=   5.8s
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.182, test=0.140) total time=  24.4s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  17.8s
[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  17.5s
[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.182, test=0.140) total time=  18.8s
[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  19.0s
[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  19.3s
[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.182, test=0.140) total time=  19.6s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.240, test=0.078) total time=  53.1s
[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.274, test=0.070) total time=  55.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.4s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.7s
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   5.6s
[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=   4.3s
[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.452, test=0.000) total time=   5.0s
[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   2.9s
[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.8s
[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.296, test=0.000) total time=   1.9s
[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=  10.0s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.600, test=0.267) total time=   5.5s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   4.7s
[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.062, test=0.000) total time=   7.3s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  19.3s
[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  36.9s
[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  19.3s
[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  18.4s
[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.209, test=0.140) total time=  19.2s
[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  19.5s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.240, test=0.078) total time=  55.1s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.304, test=0.070) total time=  54.6s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
----------
iter: 3
n_candidates: 2
n_resources: 17091
Fitting 3 folds for each of 2 candidates, totalling 6 fits
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters
  warnings.warn(
[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  20.3s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  15.0s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.197, test=0.172) total time=  54.6s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.240, test=0.078) total time=  54.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Time taken to train Logistic Regression for Remember:  875.20063996315
Best parameters for Logistic Regression for Remember:  {'C': 10, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001}
Accuracy for Logistic Regression for Remember 0.960710944808232
Accuracy Score ->  0.960710944808232
Kappa Score ->  0.5047930502494757
ROC AUC Score ->  0.6912455875885224
F1 Score ->  0.5227272727272728
Classification report -> 
               precision    recall  f1-score   support

           0       0.97      0.99      0.98      4039
           1       0.80      0.39      0.52       237

    accuracy                           0.96      4276
   macro avg       0.88      0.69      0.75      4276
weighted avg       0.96      0.96      0.95      4276

Accuracy for Logistic Regression for Remember with Auto:  0.76
Accuracy Score ->  0.76
Kappa Score ->  0.0
ROC AUC Score ->  0.5
F1 Score ->  0.0
Classification report -> 
               precision    recall  f1-score   support

           0       0.76      1.00      0.86        38
           1       0.00      0.00      0.00        12

    accuracy                           0.76        50
   macro avg       0.38      0.50      0.43        50
weighted avg       0.58      0.76      0.66        50

n_iterations: 6
n_required_iterations: 6
n_possible_iterations: 6
min_resources_: 70
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 324
n_resources: 70
Fitting 3 folds for each of 324 candidates, totalling 972 fits
[CV 3/3] END var_smoothing=1e-10;, score=(train=0.607, test=0.229) total time=   1.2s
[CV 1/3] END C=0.1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   2.5s
[CV 2/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.930, test=0.567) total time=   3.9s
[CV 3/3] END C=0.1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.5s
[CV 2/3] END C=1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   3.2s
[CV 3/3] END C=1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   3.2s
[CV 2/3] END C=1, gamma=auto, kernel=poly;, score=(train=1.000, test=0.167) total time=   3.8s
[CV 3/3] END C=1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.6s
[CV 3/3] END C=10, gamma=auto, kernel=poly;, score=(train=1.000, test=0.222) total time=   3.2s
[CV 1/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.533) total time=   4.3s
[CV 2/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.641) total time=   4.1s
[CV 3/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.926, test=0.722) total time=  40.2s
[CV 2/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.657) total time=  58.8s
[CV 1/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.716) total time= 1.5min
[CV 3/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.881, test=0.784) total time=18.6min
[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.000, test=0.000) total time=   1.5s
[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.3s
[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.6s
[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.4s
[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.100, test=0.000) total time=   4.8s
[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   3.9s
[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.231, test=0.000) total time=   0.6s
[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   3.9s
[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.4s
[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   1.0s
[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   3.8s
[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.6s
[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.452, test=0.000) total time=   4.5s
[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.160, test=0.000) total time=   1.1s
[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.7s
[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.296, test=0.000) total time=   1.7s
[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.7s
[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   1.8s
[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   7.8s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   1.1s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.452, test=0.000) total time=   5.6s
[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=(train=0.227, test=0.000) total time=   7.2s
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  18.7s
[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  37.8s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.245, test=0.000) total time=  25.8s
[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.209, test=0.140) total time=  18.5s
[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  20.0s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.209, test=0.140) total time=  16.5s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.304, test=0.070) total time=  54.8s
[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.165, test=0.130) total time=  54.7s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.439, test=0.357) total time= 2.4min
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.145, test=0.000) total time=  18.8s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  20.3s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.304, test=0.070) total time=  52.5s
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.173, test=0.129) total time= 1.3min
[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.504, test=0.354) total time= 2.5min
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.667, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
[CV 2/3] END var_smoothing=1e-10;, score=(train=0.602, test=0.219) total time=   1.6s
[CV 2/3] END C=0.1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   3.2s
[CV 2/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.641) total time=   4.6s
[CV 3/3] END C=1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   2.7s
[CV 2/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.641) total time=   4.2s
[CV 1/3] END C=10, gamma=scale, kernel=poly;, score=(train=0.031, test=0.000) total time=   3.4s
[CV 2/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.641) total time=   4.1s
[CV 2/3] END C=10, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.082) total time=   4.6s
[CV 2/3] END C=100, gamma=scale, kernel=poly;, score=(train=0.783, test=0.145) total time=   3.4s
[CV 1/3] END C=100, gamma=auto, kernel=poly;, score=(train=1.000, test=0.241) total time=   3.1s
[CV 3/3] END C=100, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.130) total time=   3.7s
[CV 1/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.716) total time=  47.9s
[CV 3/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.667) total time= 1.1min
[CV 2/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.657) total time=  52.9s
[CV 2/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.691) total time=19.4min
[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.182, test=0.143) total time=   1.3s
[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.5s
[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.100, test=0.000) total time=   4.4s
[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.160, test=0.000) total time=   0.6s
[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.5s
[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   1.3s
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   4.1s
[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   0.7s
[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.125, test=0.000) total time=   4.3s
[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=(train=0.100, test=0.000) total time=   1.6s
[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.261, test=0.143) total time=   2.8s
[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   1.6s
[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.600, test=0.267) total time=   8.8s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.125, test=0.000) total time=   4.8s
[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=(train=0.133, test=0.000) total time=   0.8s
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=(train=0.452, test=0.000) total time=   4.9s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.209, test=0.140) total time=  18.8s
[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.209, test=0.140) total time=  37.5s
[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.242, test=0.000) total time=  19.1s
[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.209, test=0.140) total time=  18.7s
[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.145, test=0.000) total time=  19.5s
[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.242, test=0.000) total time=  19.2s
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.282, test=0.070) total time= 1.3min
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.197, test=0.172) total time=  47.3s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.197, test=0.172) total time=  54.7s
[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=(train=0.215, test=0.078) total time=  54.8s
[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.173, test=0.129) total time=  49.9s
[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.504, test=0.354) total time= 2.4min
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.667, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=(train=0.359, test=0.407) total time= 2.5min
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=(train=0.215, test=0.078) total time= 1.3min
[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.282, test=0.070) total time=  59.8s
[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.439, test=0.357) total time= 2.5min
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.500, test=0.000) total time=   0.5s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=(train=0.215, test=0.078) total time=  50.0s
[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=(train=0.359, test=0.407) total time= 2.4min
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.800, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.500, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.500, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.667, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.500, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.500, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.667, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.545, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.952, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.222, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
----------
iter: 1
n_candidates: 108
n_resources: 210
Fitting 3 folds for each of 108 candidates, totalling 324 fits
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.857, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.933, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.933, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.900, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.952, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.800, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.933, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.900, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.933, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.400, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.842, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.952, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.769, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.952, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.400, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.429, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.500, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=0.778, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.625, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.545, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.222, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.857, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.778, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.900, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.778, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.625, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.900, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.842, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.167, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.400, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.429, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.842, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=0.400, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.516, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.235, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.537, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
----------
iter: 2
n_candidates: 36
n_resources: 630
Fitting 3 folds for each of 36 candidates, totalling 108 fits
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.167, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.933, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.593, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.467, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.462, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.6s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.7s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.053, test=0.000) total time=   0.6s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
----------
iter: 3
n_candidates: 12
n_resources: 1890
Fitting 3 folds for each of 12 candidates, totalling 36 fits
----------
iter: 4
n_candidates: 4
n_resources: 5670
Fitting 3 folds for each of 4 candidates, totalling 12 fits
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.308, test=0.000) total time=   0.4s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.778, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.857, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.231, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=0.882, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.414, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.9s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   4.2s
----------
iter: 5
n_candidates: 2
n_resources: 17010
Fitting 3 folds for each of 2 candidates, totalling 6 fits
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.500, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.167, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.900, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.952, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.480, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.776, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=0.757, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.571, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.026, test=0.039) total time=   1.4s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   1.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.028, test=0.019) total time=   6.9s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.509) total time=   2.6s
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
Time taken to train Random Forest for Remember:  1762.4550688266754
Best parameters for Random Forest for Remember:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}
Accuracy for Random Forest for Remember 0.9452759588400375
Accuracy Score ->  0.9452759588400375
Kappa Score ->  0.023647125635966604
ROC AUC Score ->  0.5063291139240507
F1 Score ->  0.024999999999999998
Classification report -> 
               precision    recall  f1-score   support

           0       0.95      1.00      0.97      4039
           1       1.00      0.01      0.02       237

    accuracy                           0.95      4276
   macro avg       0.97      0.51      0.50      4276
weighted avg       0.95      0.95      0.92      4276

Accuracy for Random Forest for Remember with Auto:  0.76
Accuracy Score ->  0.76
Kappa Score ->  0.0
ROC AUC Score ->  0.5
F1 Score ->  0.0
Classification report -> 
               precision    recall  f1-score   support

           0       0.76      1.00      0.86        38
           1       0.00      0.00      0.00        12

    accuracy                           0.76        50
   macro avg       0.38      0.50      0.43        50
weighted avg       0.58      0.76      0.66        50

n_iterations: 3
n_required_iterations: 3
n_possible_iterations: 3
min_resources_: 1900
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 24
n_resources: 1900
Fitting 3 folds for each of 24 candidates, totalling 72 fits
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.167, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.545, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.900, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.889, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.190, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.348, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.813, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.7s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.031, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.5s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.985, test=0.491) total time=   2.1s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.590) total time=   2.4s
[CV 2/3] END gamma=0.1, learning_rate=0.5, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.536) total time=   1.9s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.979, test=0.617) total time=   1.7s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.979, test=0.675) total time=   1.7s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=0.979, test=0.625) total time=   2.1s
[CV 3/3] END gamma=0.5, learning_rate=0.5, max_depth=5, n_estimators=50;, score=(train=1.000, test=0.473) total time=   1.5s
[CV 1/3] END gamma=0.5, learning_rate=0.5, max_depth=7, n_estimators=50;, score=(train=0.993, test=0.593) total time=   1.6s
[CV 1/3] END gamma=0.5, learning_rate=0.5, max_depth=10, n_estimators=100;, score=(train=0.993, test=0.557) total time=   1.8s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.222, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.167, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=0.500, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=(train=0.900, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.857, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.480, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.789, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.348, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.053, test=0.000) total time=   0.4s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.053, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   1.8s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   1.5s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.025, test=0.019) total time=   8.1s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.993, test=0.552) total time=   2.0s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.979, test=0.605) total time=   1.8s
[CV 3/3] END gamma=0.1, learning_rate=0.5, max_depth=5, n_estimators=50;, score=(train=1.000, test=0.542) total time=   2.2s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.985, test=0.552) total time=   2.2s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.981, test=0.561) total time=   1.6s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.979, test=0.625) total time=   1.7s
[CV 2/3] END gamma=0.5, learning_rate=0.5, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.423) total time=   2.0s
[CV 2/3] END gamma=0.5, learning_rate=0.5, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.586) total time=   1.5s
----------
iter: 1
n_candidates: 8
n_resources: 5700
Fitting 3 folds for each of 8 candidates, totalling 24 fits
[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.467, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.516, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.026, test=0.039) total time=   1.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   1.6s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   3.8s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.025, test=0.019) total time=   6.1s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.979, test=0.597) total time=   1.8s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.993, test=0.533) total time=   2.0s
[CV 2/3] END gamma=0.1, learning_rate=0.5, max_depth=5, n_estimators=50;, score=(train=1.000, test=0.545) total time=   2.2s
[CV 1/3] END gamma=0.1, learning_rate=0.5, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.538) total time=   1.9s
[CV 2/3] END gamma=0.1, learning_rate=0.5, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.586) total time=   2.0s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.961, test=0.644) total time=   1.8s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=0.979, test=0.675) total time=   2.1s
[CV 1/3] END gamma=0.5, learning_rate=0.5, max_depth=5, n_estimators=50;, score=(train=0.986, test=0.575) total time=   1.9s
[CV 2/3] END gamma=0.5, learning_rate=0.5, max_depth=7, n_estimators=50;, score=(train=1.000, test=0.423) total time=   1.6s
[CV 3/3] END gamma=0.5, learning_rate=0.5, max_depth=10, n_estimators=100;, score=(train=0.981, test=0.500) total time=   1.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.019, test=0.025) total time=   9.5s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.608) total time=   2.8s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.500) total time=   2.5s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.590) total time=   2.5s
[CV 1/3] END gamma=0.1, learning_rate=0.5, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.557) total time=   1.9s
[CV 3/3] END gamma=0.1, learning_rate=0.5, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.533) total time=   2.0s
[CV 3/3] END gamma=0.1, learning_rate=0.5, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.526) total time=   1.9s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.993, test=0.526) total time=   1.8s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=0.990, test=0.561) total time=   2.3s
[CV 1/3] END gamma=0.5, learning_rate=0.5, max_depth=5, n_estimators=100;, score=(train=0.986, test=0.575) total time=   1.8s
[CV 1/3] END gamma=0.5, learning_rate=0.5, max_depth=7, n_estimators=100;, score=(train=0.993, test=0.593) total time=   1.9s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.979, test=0.708) total time=   8.9s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=0.995, test=0.773) total time=  11.7s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.942, test=0.714) total time=   8.1s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.983, test=0.767) total time=   8.9s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.984, test=0.705) total time=  10.4s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.950, test=0.758) total time=   6.5s
----------
iter: 2
n_candidates: 3
n_resources: 17100
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.667, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.952, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.000) total time=   0.0s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.0s
[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=1.000, test=0.000) total time=   0.3s
[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.100, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=(train=0.571, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.848, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.850, test=0.000) total time=   0.1s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=(train=0.800, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.1s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.7s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   1.8s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   4.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.025, test=0.019) total time=   7.1s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.961, test=0.517) total time=   2.3s
[CV 2/3] END gamma=0.1, learning_rate=0.5, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.545) total time=   2.0s
[CV 3/3] END gamma=0.1, learning_rate=0.5, max_depth=7, n_estimators=50;, score=(train=1.000, test=0.533) total time=   1.6s
[CV 2/3] END gamma=0.1, learning_rate=0.5, max_depth=10, n_estimators=50;, score=(train=1.000, test=0.586) total time=   1.6s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.977, test=0.552) total time=   2.3s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.993, test=0.473) total time=   1.8s
[CV 3/3] END gamma=0.5, learning_rate=0.5, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.473) total time=   1.9s
[CV 2/3] END gamma=0.5, learning_rate=0.5, max_depth=10, n_estimators=50;, score=(train=1.000, test=0.586) total time=   1.5s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.978, test=0.759) total time=   6.8s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.975, test=0.755) total time=   8.3s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.988, test=0.769) total time=  10.3s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.959, test=0.773) total time=   5.1s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.2s
[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=(train=0.000, test=0.000) total time=   0.3s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.000, test=0.000) total time=   0.4s
[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=(train=0.000, test=0.000) total time=   0.8s
[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.000, test=0.000) total time=   1.2s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.000, test=0.000) total time=   1.8s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.979, test=0.590) total time=   1.9s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.500) total time=   2.4s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.552) total time=   2.5s
[CV 1/3] END gamma=0.1, learning_rate=0.5, max_depth=7, n_estimators=50;, score=(train=1.000, test=0.538) total time=   1.6s
[CV 3/3] END gamma=0.1, learning_rate=0.5, max_depth=10, n_estimators=50;, score=(train=1.000, test=0.526) total time=   1.5s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=0.981, test=0.571) total time=   2.1s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=0.993, test=0.526) total time=   2.1s
[CV 3/3] END gamma=0.5, learning_rate=0.5, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.483) total time=   1.9s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.980, test=0.761) total time=   8.0s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=0.998, test=0.765) total time=  12.0s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.979, test=0.714) total time=  11.7s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.975, test=0.768) total time=  31.0s
[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.019, test=0.025) total time=   5.0s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.990, test=0.552) total time=   1.9s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.990, test=0.567) total time=   1.7s
[CV 1/3] END gamma=0.1, learning_rate=0.5, max_depth=5, n_estimators=50;, score=(train=1.000, test=0.557) total time=   1.7s
[CV 2/3] END gamma=0.1, learning_rate=0.5, max_depth=7, n_estimators=50;, score=(train=1.000, test=0.536) total time=   1.6s
[CV 1/3] END gamma=0.1, learning_rate=0.5, max_depth=10, n_estimators=50;, score=(train=1.000, test=0.538) total time=   1.6s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.961, test=0.571) total time=   2.0s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.473) total time=   2.1s
[CV 2/3] END gamma=0.5, learning_rate=0.5, max_depth=5, n_estimators=50;, score=(train=1.000, test=0.533) total time=   1.8s
[CV 3/3] END gamma=0.5, learning_rate=0.5, max_depth=7, n_estimators=50;, score=(train=1.000, test=0.483) total time=   1.5s
[CV 1/3] END gamma=0.5, learning_rate=0.5, max_depth=10, n_estimators=50;, score=(train=0.993, test=0.557) total time=   1.5s
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50;, score=(train=0.976, test=0.703) total time=   5.5s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=0.995, test=0.697) total time=  10.9s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.985, test=0.751) total time=  10.8s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.921, test=0.785) total time=  36.6s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.974, test=0.815) total time=  12.7s
Time taken to train XGBoost for Remember:  277.5375061035156
Best parameters for XGBoost for Remember:  {'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}
Accuracy for XGBoost for Remember 0.9819925163704397
Accuracy Score ->  0.9819925163704397
Kappa Score ->  0.8276784648848265
ROC AUC Score ->  0.9130173843005381
F1 Score ->  0.8372093023255814
Classification report -> 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99      4039
           1       0.84      0.84      0.84       237

    accuracy                           0.98      4276
   macro avg       0.91      0.91      0.91      4276
weighted avg       0.98      0.98      0.98      4276

Accuracy for XGBoost for Remember with Auto:  0.74
Accuracy Score ->  0.74
Kappa Score ->  -0.03833865814696491
ROC AUC Score ->  0.4868421052631579
F1 Score ->  0.0
Classification report -> 
               precision    recall  f1-score   support

           0       0.76      0.97      0.85        38
           1       0.00      0.00      0.00        12

    accuracy                           0.74        50
   macro avg       0.38      0.49      0.43        50
weighted avg       0.57      0.74      0.65        50

Running models for Understand task...
n_iterations: 2
n_required_iterations: 2
n_possible_iterations: 2
min_resources_: 5701
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 3
n_resources: 5701
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.982, test=0.791) total time=  35.1s
[CV 2/3] END var_smoothing=1e-10;, score=(train=0.636, test=0.529) total time=   0.8s
----------
iter: 1
n_candidates: 1
n_resources: 17103
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.989, test=0.708) total time=  10.2s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=0.998, test=0.752) total time=  12.3s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.985, test=0.766) total time=  11.9s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.919, test=0.794) total time=  39.2s
[CV 1/3] END var_smoothing=1e-08;, score=(train=0.666, test=0.520) total time=   0.9s
[CV 2/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.918, test=0.698) total time=   6.0s
[CV 1/3] END C=1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   4.9s
[CV 1/3] END C=1, gamma=auto, kernel=linear;, score=(train=1.000, test=0.658) total time=   9.3s
[CV 3/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.750) total time=  12.0s
[CV 3/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.750) total time=  12.3s
[CV 2/3] END C=100, gamma=scale, kernel=poly;, score=(train=0.863, test=0.414) total time=   5.3s
[CV 3/3] END C=100, gamma=auto, kernel=poly;, score=(train=1.000, test=0.585) total time=   7.7s
[CV 1/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.725) total time= 2.1min
/opt/anaconda3/envs/CLO/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
Time taken to train Naive Bayes for Understand:  24.705461025238037
Best parameters for Naive Bayes for Understand:  {'var_smoothing': 1e-08}
Accuracy for Naive Bayes for Understand 0.6454630495790459
Accuracy Score ->  0.6454630495790459
Kappa Score ->  0.33127067336577254
ROC AUC Score ->  0.7174913307325532
F1 Score ->  0.5825991189427313
Classification report -> 
               precision    recall  f1-score   support

           0       0.92      0.55      0.69      3076
           1       0.44      0.88      0.58      1200

    accuracy                           0.65      4276
   macro avg       0.68      0.72      0.64      4276
weighted avg       0.79      0.65      0.66      4276

Accuracy for Naive Bayes for Understand with Auto:  0.78
Accuracy Score ->  0.78
Kappa Score ->  0.1887905604719763
ROC AUC Score ->  0.5701754385964912
F1 Score ->  0.26666666666666666
Classification report -> 
               precision    recall  f1-score   support

           0       0.79      0.97      0.87        38
           1       0.67      0.17      0.27        12

    accuracy                           0.78        50
   macro avg       0.73      0.57      0.57        50
weighted avg       0.76      0.78      0.73        50

n_iterations: 3
n_required_iterations: 3
n_possible_iterations: 3
min_resources_: 1900
max_resources_: 17104
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 24
n_resources: 1900
Fitting 3 folds for each of 24 candidates, totalling 72 fits
----------
iter: 1
n_candidates: 8
n_resources: 5700
Fitting 3 folds for each of 8 candidates, totalling 24 fits
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.990, test=0.775) total time=   9.4s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=0.992, test=0.745) total time=  12.2s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.870, test=0.806) total time=  35.3s
[CV 1/3] END var_smoothing=1e-09;, score=(train=0.645, test=0.511) total time=   1.0s
[CV 3/3] END var_smoothing=1e-08;, score=(train=0.614, test=0.575) total time=   2.9s
[CV 1/3] END C=0.1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.7s
[CV 2/3] END C=0.1, gamma=auto, kernel=poly;, score=(train=0.879, test=0.423) total time=   4.7s
[CV 2/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.997, test=0.682) total time=  10.0s
[CV 3/3] END C=1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   5.3s
[CV 1/3] END C=1, gamma=auto, kernel=rbf;, score=(train=0.507, test=0.085) total time=   6.4s
[CV 3/3] END C=10, gamma=scale, kernel=poly;, score=(train=0.529, test=0.333) total time=   5.3s
[CV 2/3] END C=10, gamma=auto, kernel=poly;, score=(train=1.000, test=0.548) total time=   6.2s
[CV 3/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.750) total time=  12.0s
[CV 1/3] END C=100, gamma=auto, kernel=poly;, score=(train=1.000, test=0.500) total time=   7.4s
[CV 3/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.982, test=0.774) total time= 1.3min
[CV 2/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.734) total time= 2.2min
[CV 2/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.903, test=0.809) total time=  50.4s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=1.000, test=0.586) total time=   2.5s
[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.517) total time=   2.7s
[CV 3/3] END gamma=0.1, learning_rate=0.5, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.542) total time=   1.9s
[CV 1/3] END gamma=0.1, learning_rate=0.5, max_depth=10, n_estimators=100;, score=(train=1.000, test=0.538) total time=   1.8s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.979, test=0.617) total time=   2.0s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.981, test=0.571) total time=   1.7s
[CV 2/3] END gamma=0.5, learning_rate=0.5, max_depth=5, n_estimators=100;, score=(train=1.000, test=0.533) total time=   1.9s
[CV 3/3] END gamma=0.5, learning_rate=0.5, max_depth=10, n_estimators=50;, score=(train=0.981, test=0.500) total time=   1.6s
[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=50;, score=(train=0.987, test=0.769) total time=   9.6s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=0.987, test=0.703) total time=  11.1s
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.982, test=0.751) total time=  12.3s
[CV 2/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.868, test=0.776) total time=  35.7s
[CV 3/3] END var_smoothing=1e-08;, score=(train=0.658, test=0.530) total time=   1.2s
[CV 1/3] END C=0.1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   4.7s
[CV 3/3] END C=0.1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   7.0s
[CV 2/3] END C=1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.9s
[CV 2/3] END C=1, gamma=auto, kernel=rbf;, score=(train=0.460, test=0.092) total time=   6.5s
[CV 1/3] END C=10, gamma=scale, kernel=rbf;, score=(train=0.447, test=0.225) total time=   5.9s
[CV 1/3] END C=10, gamma=auto, kernel=rbf;, score=(train=0.992, test=0.351) total time=   7.8s
[CV 3/3] END C=100, gamma=scale, kernel=poly;, score=(train=0.867, test=0.521) total time=   5.3s
[CV 3/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.750) total time=  11.8s
[CV 1/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.985, test=0.760) total time= 1.9min
[CV 2/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.734) total time= 2.1min
[CV 3/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.896, test=0.812) total time=  49.7s
[CV 1/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=50;, score=(train=0.877, test=0.783) total time=  35.5s
[CV 2/3] END var_smoothing=1e-08;, score=(train=0.676, test=0.537) total time=   1.0s
[CV 3/3] END var_smoothing=1e-09;, score=(train=0.630, test=0.517) total time=   1.0s
[CV 1/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.936, test=0.664) total time=   4.2s
[CV 2/3] END C=0.1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   4.5s
[CV 3/3] END C=0.1, gamma=auto, kernel=poly;, score=(train=0.885, test=0.526) total time=   4.8s
[CV 3/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.999, test=0.749) total time=  11.1s
[CV 2/3] END C=1, gamma=auto, kernel=linear;, score=(train=0.997, test=0.682) total time=  10.1s
[CV 3/3] END C=1, gamma=auto, kernel=rbf;, score=(train=0.573, test=0.141) total time=   6.8s
[CV 2/3] END C=10, gamma=scale, kernel=rbf;, score=(train=0.418, test=0.152) total time=   5.3s
[CV 3/3] END C=10, gamma=auto, kernel=poly;, score=(train=1.000, test=0.585) total time=   7.9s
[CV 1/3] END C=100, gamma=scale, kernel=poly;, score=(train=0.892, test=0.480) total time=   5.3s
[CV 2/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.683) total time=  10.5s
[CV 1/3] END C=1, gamma=auto, kernel=linear;, score=(train=0.985, test=0.760) total time= 1.9min
[CV 1/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.721) total time= 2.3min
[CV 1/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.905, test=0.807) total time=  50.1s
----------
iter: 2
n_candidates: 3
n_resources: 17100
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV 2/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.889, test=0.845) total time=93.6min
[CV 2/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.889, test=0.845) total time=94.0min
[CV 3/3] END var_smoothing=1e-10;, score=(train=0.615, test=0.507) total time=   0.6s
[CV 2/3] END var_smoothing=1e-08;, score=(train=0.616, test=0.573) total time=   3.1s
[CV 3/3] END C=0.1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   4.8s
[CV 3/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.916, test=0.772) total time=   6.3s
[CV 1/3] END C=1, gamma=scale, kernel=linear;, score=(train=1.000, test=0.658) total time=  10.0s
[CV 3/3] END C=1, gamma=auto, kernel=linear;, score=(train=0.999, test=0.749) total time=  11.7s
[CV 2/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.683) total time=  10.6s
[CV 1/3] END C=10, gamma=auto, kernel=poly;, score=(train=1.000, test=0.500) total time=   7.9s
[CV 1/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.658) total time=  10.7s
[CV 2/3] END C=100, gamma=scale, kernel=rbf;, score=(train=0.865, test=0.435) total time=   5.3s
[CV 2/3] END C=100, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.355) total time=   5.9s
[CV 2/3] END C=1, gamma=auto, kernel=linear;, score=(train=0.978, test=0.779) total time= 1.4min
[CV 1/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.725) total time= 2.0min
[CV 3/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.727) total time= 1.9min
[CV 1/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.890, test=0.841) total time=95.0min
[CV 3/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.727) total time= 2.0min
[CV 2/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.903, test=0.809) total time=  46.6s
[CV 3/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.894, test=0.848) total time=96.7min
[CV 2/3] END var_smoothing=1e-09;, score=(train=0.651, test=0.535) total time=   0.9s
[CV 1/3] END var_smoothing=1e-08;, score=(train=0.622, test=0.564) total time=   3.0s
[CV 2/3] END C=0.1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   4.8s
[CV 1/3] END C=0.1, gamma=auto, kernel=poly;, score=(train=0.900, test=0.488) total time=   4.7s
[CV 2/3] END C=1, gamma=scale, kernel=poly;, score=(train=0.000, test=0.000) total time=   4.6s
[CV 1/3] END C=1, gamma=auto, kernel=poly;, score=(train=0.998, test=0.497) total time=   7.8s
[CV 1/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.658) total time=  10.3s
[CV 3/3] END C=10, gamma=scale, kernel=rbf;, score=(train=0.520, test=0.305) total time=   5.6s
[CV 3/3] END C=10, gamma=auto, kernel=rbf;, score=(train=0.997, test=0.400) total time=   8.2s
[CV 3/3] END C=100, gamma=scale, kernel=rbf;, score=(train=0.860, test=0.476) total time=   5.6s
[CV 1/3] END C=100, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.359) total time=   7.0s
[CV 3/3] END C=1, gamma=auto, kernel=linear;, score=(train=0.982, test=0.774) total time= 1.3min
[CV 3/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.727) total time= 2.1min
[CV 2/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.734) total time= 2.0min
[CV 2/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.938, test=0.839) total time=106.0min
[CV 3/3] END gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=0.921, test=0.810) total time=  41.7s
[CV 1/3] END var_smoothing=1e-10;, score=(train=0.634, test=0.505) total time=   0.9s
[CV 2/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.918, test=0.698) total time=   4.8s
[CV 3/3] END C=0.1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   5.2s
[CV 1/3] END C=0.1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   6.0s
[CV 3/3] END C=1, gamma=scale, kernel=poly;, score=(train=0.074, test=0.012) total time=   5.1s
[CV 3/3] END C=1, gamma=auto, kernel=poly;, score=(train=1.000, test=0.572) total time=   7.5s
[CV 1/3] END C=10, gamma=scale, kernel=poly;, score=(train=0.522, test=0.283) total time=   5.1s
[CV 1/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.658) total time=  10.3s
[CV 2/3] END C=10, gamma=auto, kernel=rbf;, score=(train=0.994, test=0.374) total time=   7.7s
[CV 1/3] END C=100, gamma=scale, kernel=rbf;, score=(train=0.871, test=0.441) total time=   5.6s
[CV 2/3] END C=100, gamma=auto, kernel=poly;, score=(train=1.000, test=0.548) total time=   6.2s
[CV 2/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.978, test=0.779) total time= 1.5min
[CV 3/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.727) total time= 2.1min
[CV 1/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.905, test=0.807) total time=  54.5s
[CV 1/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.939, test=0.833) total time=106.5min
[CV 3/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.916, test=0.772) total time=   6.5s
[CV 1/3] END C=0.1, gamma=auto, kernel=linear;, score=(train=0.936, test=0.664) total time=   6.0s
[CV 2/3] END C=0.1, gamma=auto, kernel=rbf;, score=(train=0.000, test=0.000) total time=   6.4s
[CV 1/3] END C=1, gamma=scale, kernel=rbf;, score=(train=0.000, test=0.000) total time=   5.1s
[CV 2/3] END C=1, gamma=auto, kernel=poly;, score=(train=0.997, test=0.551) total time=   7.4s
[CV 2/3] END C=10, gamma=scale, kernel=poly;, score=(train=0.473, test=0.206) total time=   5.0s
[CV 2/3] END C=10, gamma=auto, kernel=linear;, score=(train=1.000, test=0.683) total time=  10.8s
[CV 2/3] END C=100, gamma=scale, kernel=linear;, score=(train=1.000, test=0.683) total time=  11.0s
[CV 1/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.658) total time=  10.0s
[CV 3/3] END C=100, gamma=auto, kernel=rbf;, score=(train=1.000, test=0.403) total time=   5.4s
[CV 2/3] END C=10, gamma=scale, kernel=linear;, score=(train=1.000, test=0.734) total time= 2.2min
[CV 1/3] END C=100, gamma=auto, kernel=linear;, score=(train=1.000, test=0.721) total time= 2.3min
[CV 3/3] END C=0.1, gamma=scale, kernel=linear;, score=(train=0.896, test=0.812) total time=  39.7s
[CV 3/3] END C=1, gamma=scale, kernel=linear;, score=(train=0.939, test=0.832) total time=106.7min
